{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 02 - Parte 1 - Expansão de Consultas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indice invertido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método a seguir permite construir um indice invertido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import pandas as p\n",
    "import numpy as np\n",
    "from unicodedata import normalize\n",
    "from scipy import sparse\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "def build_inverted_index(data):\n",
    "    inverted_index = {}\n",
    "    for index, doc in data.iteritems():\n",
    "        doc = doc.lower()\n",
    "        words = [clear_text(word) for word in nltk.word_tokenize(doc)]\n",
    "        words = [str(word) for word in words]\n",
    "        for word in words:\n",
    "            inverted_index.setdefault(word, []).append(index + 1)\n",
    "            \n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método remove todos os caracteres especiais do texto bem como sua acentuação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    pattern = re.compile('[^a-zA-Z0-9 ]')\n",
    "    text = normalize('NFKD', text).encode('ASCII', 'ignore').decode('ASCII')\n",
    "    return pattern.sub(' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementação dos métodos de busca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando um método de busca genérico podendo receber pesquisas com *n* termos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(inverted_index, term):\n",
    "    terms = [normalize('NFKD', word.decode('utf-8')).encode('ASCII', 'ignore') for word in nltk.word_tokenize(term.lower())]\n",
    "    if len(terms) >= 1:\n",
    "        return _search_or(inverted_index, terms)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodo de busca *or* com *n* termos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _search_or(inverted_index, terms):\n",
    "    result_set = set(inverted_index[terms[0]])\n",
    "    for term in terms[1:]:\n",
    "        result_set = result_set.union(set(inverted_index[term]))\n",
    "    return list(result_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodo que permite  contruir a matrix de termos-termos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrence_matrix(corpus):\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    n = len(vocab)\n",
    "   \n",
    "    vocab_to_index = {word:i for i, word in enumerate(vocab)}\n",
    "    \n",
    "    bi_grams = list(bigrams(corpus))\n",
    "\n",
    "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
    "\n",
    "    I=list()\n",
    "    J=list()\n",
    "    V=list()\n",
    "    \n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1]\n",
    "        previous = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "\n",
    "        I.append(vocab_to_index[previous])\n",
    "        J.append(vocab_to_index[current])\n",
    "        V.append(count)\n",
    "        \n",
    "    co_occurrence_matrix = sparse.coo_matrix((V,(I,J)), shape=(n,n))\n",
    "\n",
    "    return co_occurrence_matrix, vocab_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação do data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = p.read_csv(\"data-set/estadao_noticias_eleicao.csv\", encoding = \"utf-8\")\n",
    "data = data.replace(np.NAN, \"\")\n",
    "content = data.titulo + \" \" + data.subTitulo + \" \" + data.conteudo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo pontuação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens_lists = content.apply(lambda text: tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removendo stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_ = stopwords.words('portuguese')\n",
    "filtered_tokens = tokens_lists.apply(lambda tokens: [token for token in tokens if token not in stopword_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Construção da  matrix de termos-termos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformando lista de listas em uma lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token for tokens_list in filtered_tokens for token in tokens_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, vocab = co_occurrence_matrix(tokens)\n",
    "consultable_matrix = matrix.tocsr()\n",
    "inverted_vocab = {vocab[key]: key for key in vocab}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Metodo que retorna as top-3 palavras mais frequentes de acordo com a matriz de ocorrência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_co_ocurrences(co_matrix, inv_vocab, term, N = 3):\n",
    "    np_array = np.reshape(co_matrix[term].toarray(), -1)\n",
    "    return list(OrderedDict({inv_vocab[idx]: np_array[idx] for idx in (-np_array).argsort()[:N]}).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Metodo que expande a consulta original com os termos retornados no passo 2 acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanded_query(terms):\n",
    "    query = []\n",
    "    terms = [normalize('NFKD', word.decode('utf-8')).encode('ASCII', 'ignore') for word in nltk.word_tokenize(terms.lower())]\n",
    "    if len(terms) > 1:\n",
    "        for term in terms:\n",
    "            query.append(term)\n",
    "            query.extend(get_co_ocurrences(consultable_matrix, inverted_vocab, vocab[term]))    \n",
    "    else:\n",
    "        query.append(terms[0])\n",
    "        query.extend(get_co_ocurrences(consultable_matrix, inverted_vocab, vocab[terms[0]]))    \n",
    "    \n",
    "    return \" \".join(term for term in set(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Fazer uma busca disjuntiva (OR) considerando a nova consulta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chamada ao método de contrução de indice invertido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index_values = build_inverted_index(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Respondendo às perguntas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quais os termos retornados para a expansão de cada consulta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query original: candidatos\n",
      "Número de documentos retornados na consulta original: 1428\n",
      "Query expandida: governo presidência candidatos oposição\n",
      "Número de documentos retornados na consulta expandida: 6070\n",
      "Query original: debate presidencial \n",
      "Número de documentos retornados na consulta original: 1804\n",
      "Query expandida: deste sobre 2010 aécio eleitoral político debate presidencial\n",
      "Número de documentos retornados na consulta expandida: 6953\n",
      "Query original: corruptos\n",
      "Número de documentos retornados na consulta original: 53\n",
      "Query expandida: partido corruptores corruptos disse\n",
      "Número de documentos retornados na consulta expandida: 5614\n",
      "Query original: compra voto\n",
      "Número de documentos retornados na consulta original: 1657\n",
      "Query expandida: dilma distrital refinaria voto pasadena votos compra presidente\n",
      "Número de documentos retornados na consulta expandida: 6151\n",
      "Query original: partidos\n",
      "Número de documentos retornados na consulta original: 1685\n",
      "Query expandida: políticos base aliados partidos\n",
      "Número de documentos retornados na consulta expandida: 3965\n",
      "Query original: regime semiaberto\n",
      "Número de documentos retornados na consulta original: 374\n",
      "Query expandida: semiaberto pena crimes jefferson fechado regime militar\n",
      "Número de documentos retornados na consulta expandida: 1358\n"
     ]
    }
   ],
   "source": [
    "queries = ['candidatos', 'debate presidencial ', 'corruptos', 'compra voto', 'partidos', 'regime semiaberto']\n",
    "expand_query = []\n",
    "for query in queries:\n",
    "    ext_query = expanded_query(query)\n",
    "    expand_query.append(ext_query)\n",
    "    print 'Query original: %s' % query\n",
    "    print 'Número de documentos retornados na consulta original: %d' % len(search(inverted_index_values, query))\n",
    "    print 'Query expandida: %s' % ext_query\n",
    "    print 'Número de documentos retornados na consulta expandida: %d' % len(search(inverted_index_values, ext_query.encode('utf8')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Você acha que esses termos são de fato relacionados com a consulta original? Justifique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os termos retornados pelo método *expanded_query* estão relacionados de certa forma com os termos da consulta original pois esses termos são os que mais aparecem em conjunto com a busca desejada e podem se gerar uma maior aproximação com o que se deseja pesquisar. Podemos ver com mais clareza nas consultas: *partidos* , *compra voto*, *corruptos*, *candidatos* essa aproximação. Outra ponto que podemos observar é que a quantidade de documentos retornados pela consulta expandida, trazendo muito mais documentos complementando assim a pesquisa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare os documentos retornados para a consulta original com a consulta expandida. Quais resultados você acha que melhor capturam a necessidade de informação do usuário? Por que?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A consulta expandida retorna resultados melhores, pois usa os termos que estão mais relacionados com a consulta original, ficando mais significativa e retornando resultados de possíveis palavras que o usuário poderia usar para melhoras as proximas consultas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A expansão de consultas é mais adequada para melhorar o recall ou o precision? Por que?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a consulta expandinda o recall melhora, já que o recall é a razão entre o total de documentos relevantes na busca e a quantidade total de documentos relevantes, ou seja, quanto maior for a quantidade de documentos retornados maior será a quantidade de documentos relevantes. Entretando a precisão com um recall alto irá diminui já que ela é a razão entre a quantidade de documentos relevantes na busca e a quantidade de documentos totais presentes na busca."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
